{
    "collab_server" : "",
    "contents" : "setwd(\"C:/Users/HJJeong/Desktop/experiment/R\")\n\nlibrary(randomForest)\n#library(wsrf)\n\ncomment= \"weight true wsrf\"\n# filename: 160503 hasDisease pathlen2_cn_ncn_a1_final_test_0.csv\n\ndate = \"161004\"\noption = \" undersampling10_clusterpathlen3_levelcolleague_\";\ntypearr= c(\"TG_DI\")# c(\"hasDisease\", \"causeDisease\", \"hasSubstructure\",\"hasGeneFamily\",\"causeSideEffect\", \"expressIn\",\"hasPathway\", \"hasChemicalOntology\", \"express\", \"proteinProteinInteraction\");\n\ntotal_tp=0;\ntotal_tn=0;\ntotal_fp=0;\ntotal_fn=0;\n\n#type_corr = FALSE\nhn = TRUE\ncolleague = TRUE\nwei = TRUE\nwsrf_on = TRUE\n\ntest_opt = \"path count_\";\n\nif(hn){\n  test_opt = paste(test_opt,\"hn_\",sep=\"\")\n}\nif(colleague){\n  test_opt = paste(test_opt,\"colleague\",sep=\"\")\n}\nif(wei){\n  test_opt = paste(test_opt,\"wsrf_\",sep=\"\")\n}\n\nfile_dir = \"D:/workspace/LinkPredictionRefactoring_data/new_result/korea_level/\";\n\nfileConn <- file(paste(file_dir,  \"result.txt\", sep=\"\"), open=\"at\")\n\nwriteLines(paste(\"====================typecorr:\", type_corr, \"common neighbor:\", common_neighbor, \"====================\",\"ncn :\", ncn, \"====================\", \"wsrf_on:\", wsrf_on, sep=\"\\t\"), con=fileConn)\nwriteLines(option, fileConn);\nwriteLines(comment, fileConn);\nfor (k in (1:length(typearr)))\n{\n  \n  total_tp=0;\n  total_tn=0;\n  total_fp=0;\n  total_fn=0;\n  \n  \n  type = typearr[k]\n  file_path = paste(file_dir, date,\" \", type,option, sep=\"\");\n  \n  type_corr_file_path = paste(\"./type_corr/TypeCorr \", type, \".csv\"  , sep=\"\");\n  \n  # load type corr value\n  type_corr_table = read.csv(file=type_corr_file_path, header=FALSE, sep=\",\")\n  \n  for (i in (0:9))\n  {\n    \n    file_name_train = paste(file_path, \"train_\", i, \".csv\", sep=\"\"); \n    \n    # table-format data from a file named file_name_train \n    table_train = read.csv(file=file_name_train, header = FALSE)\n\n    if (hn && colleague)\n    {\n      idx = (3:(length(table_train[1,])-1))\n    }\n    else if(hn && !colleague){\n      idx = (3:(length(table_train[1,])-7))\n    }\n    else if (!hn && !colleague){\n      idx = (3:(length(table_train[1,])-9))\n    }\n    train=table_train[,idx]\n    \n    # multiply type corr value\n    if(type_corr)\n    {\n      for (j in (1:length(type_corr_table[1,])))\n      {\n        train[,j] = table_train[,j+2]*type_corr_table[1,j]\n      }\n      \n      # common neighbor\n      if(nrc && common_neighbor && ncn){\n        train[,length(train[1,])-8] = table_train[,length(table_train[1,])-9]\n        train[,length(train[1,])-7] = table_train[,length(table_train[1,])-8]\n        train[,length(train[1,])-6] = table_train[,length(table_train[1,])-7]\n        train[,length(train[1,])-5] = table_train[,length(table_train[1,])-6]\n       \n        train[,length(train[1,])-4] = table_train[,length(table_train[1,])-5]\n        train[,length(train[1,])-3] = table_train[,length(table_train[1,])-4]\n        train[,length(train[1,])-2] = table_train[,length(table_train[1,])-3]\n        train[,length(train[1,])-1] = table_train[,length(table_train[1,])-2]\n        \n        train[,length(train[1,])] = table_train[,length(table_train[1,])-1]\n      }\n      if (nrc && common_neighbor && !ncn)\n      {\n        train[,length(train[1,])-3] = table_train[,length(table_train[1,])-4]\n        train[,length(train[1,])-2] = table_train[,length(table_train[1,])-3]\n        \n        train[,length(train[1,])-1] = table_train[,length(table_train[1,])-2]\n        train[,length(train[1,])] = table_train[,length(table_train[1,])-1]\n      }else  if (nrc && !common_neighbor && !ncn)\n      {\n        train[,length(train[1,])-1] = table_train[,length(table_train[1,])-2]\n        train[,length(train[1,])] = table_train[,length(table_train[1,])-1]\n      }else\n      {\n        # nothing\n      }\n    }\n    \n    \n    # to make a model for classification, add label value as factor\n    train[,length(train[1,])+1] = as.factor(table_train[,length(table_train[1,])])\n    colnames(train)[length(train[1,])] <- \"label\"\n    \n    \n    file_name_test = paste(file_path, \"test_\", i, \".csv\", sep=\"\");\n    table_test = read.csv(file=file_name_test, header=FALSE)\n    \n    test=table_test[,idx]\n    \n    if(type_corr)\n    { \n      # multiply type corr value\n      for (j in (1:length(type_corr_table[1,])))\n      {\n        test[,j] = table_test[,j+2]*type_corr_table[1,j]\n      }\n      # common neighbor\n      if(nrc && common_neighbor &&ncn){\n        test[,length(test[1,])-8] = table_test[,length(table_test[1,])-9]\n        test[,length(test[1,])-7] = table_test[,length(table_test[1,])-8]\n        test[,length(test[1,])-6] = table_test[,length(table_test[1,])-7]\n\n        test[,length(test[1,])-5] = table_test[,length(table_test[1,])-6]\n        test[,length(test[1,])-4] = table_test[,length(table_test[1,])-5]\n        test[,length(test[1,])-3] = table_test[,length(table_test[1,])-4]\n        \n        test[,length(test[1,])-2] = table_test[,length(table_test[1,])-3]\n        test[,length(test[1,])-1] = table_test[,length(table_test[1,])-2]\n        test[,length(test[1,])] = table_test[,length(table_test[1,])-1]\n      }\n      else if (nrc && common_neighbor && !ncn)\n      {\n        test[,length(test[1,])-3] = table_test[,length(table_test[1,])-4]\n        test[,length(test[1,])-2] = table_test[,length(table_test[1,])-3]\n        \n        test[,length(test[1,])-1] = table_test[,length(table_test[1,])-2]\n        test[,length(test[1,])] = table_test[,length(table_test[1,])-1]\n      }else  if (nrc && !common_neighbor && !ncn)\n      {\n        test[,length(test[1,])-1] = table_test[,length(table_test[1,])-2]\n        test[,length(test[1,])] = table_test[,length(table_test[1,])-1]\n      }else\n      {\n        # nothing\n      }\n    }\n    \n    test_label = as.factor(table_test[,length(table_test[1,])])\n    \n    \n    if(wsrf_on)\n    {\n      model.wsrf <- wsrf(label~., data = train, weights = wei, importance = TRUE, ntrees = 100)\n      result <- predict.wsrf(model.wsrf, newdata = test, type=c(\"response\"))#prob, response\n      #probs_result <- cbind(result,test_label)\n      \n      #file_write_name = paste(file_dir, date,\" \", type, option, test_opt, sep=\"\");\n      #write.table(x=probs_result, file=paste(file_write_name, \"probability.csv\", sep=\"_\"), sep=\",\", col.names = FALSE, row.names = FALSE, append = TRUE)\n      \n      # of TP\n      tp_row = result==1 & test_label==1\n      tp = length(test[tp_row,1])\n      total_tp  = total_tp + tp;\n      # of TN\n      tn_row=result==0 & test_label==0\n      tn = length(test[tn_row,1])\n      total_tn = total_tn + tn;\n      # of FP\n      fp_row=result==1 &test_label==0\n      fp = length(test[fp_row,1])\n      total_fp = total_fp + fp;\n      # of FN\n      fn_row=result==0 & test_label==1\n      fn = length(test[fn_row,1])\n      total_fn = total_fn + fn;\n    }else\n    {\n      model <- randomForest(label~., data=train, importance=TRUE, proximity=FALSE, ntree=100)\n      result <- predict(model, newdata = test, predict.all=TRUE)\n      \n      # of TP\n      tp_row = result$aggregate==1 & test_label==1\n      tp = length(test[tp_row,1])\n      total_tp  = total_tp + tp;\n      # of TN\n      tn_row=result$aggregate==0 & test_label==0\n      tn = length(test[tn_row,1])\n      total_tn = total_tn + tn;\n      # of FP\n      fp_row=result$aggregate==1 &test_label==0\n      fp = length(test[fp_row,1])\n      total_fp = total_fp + fp;\n      # of FN\n      fn_row=result$aggregate==0 & test_label==1\n      fn = length(test[fn_row,1])\n      total_fn = total_fn + fn;\n    }\n    \n    \n    #accuracy \n    accuracy= (tp+tn)/(tp+tn+fp+fn)\n    #precision\n    precision = tp/(tp+fp)\n    #recall\n    recall = tp/(tp+fn)\n    \n    \n    # paste(\"[Acc:\",accuracy, \"][Prc:\", precision, \"(\", tp,\"/\",fp, \")\",\"][Rcl:\", recall,\"(\", tp,\"/\",tn, \")\",\"]\")\n    print(paste(accuracy, precision, recall,  paste(tp,\"/\",fp, sep=\"\"), paste(tp,\"/\",tn, sep=\"\"), sep=\",\"));\n    \n    #\n    #write.table(x = table_test[tp_row,],file=paste(file_write_name, \"tp.csv\", sep=\"_\"), append = TRUE, sep=\",\", col.names = FALSE, row.names = FALSE)\n    #write.table(x = table_test[tn_row,],file=paste(file_write_name, \"tn.csv\", sep=\"_\"), append = TRUE, sep=\",\", col.names = FALSE, row.names = FALSE)\n    #write.table(x = table_test[fp_row,],file=paste(file_write_name, \"fp.csv\", sep=\"_\"), append = TRUE, sep=\",\", col.names = FALSE, row.names = FALSE)\n    #write.table(x = table_test[fn_row,], file=paste(file_write_name, \"fn.csv\", sep=\"_\"), append = TRUE, sep=\",\", col.names = FALSE, row.names = FALSE)\n    #print(paste(i, \"th finished in \", type))\n  }\n  #accuracy \n  accuracy= (total_tp+total_tn)/(total_tp+total_tn+total_fp+total_fn)\n  #precision\n  precision = total_tp/(total_tp+total_fp)\n  #recall\n  recall = total_tp/(total_tp+total_fn)\n  fscore=2*(precision*recall)/(precision+recall)\n\n  \n  result = paste(accuracy, fscore, precision, recall,  paste(total_tp,\"/\",total_tp+total_fp, sep=\"\"), paste(total_tp,\"/\", total_tp+total_fn, sep=\"\"), sep=\",\")\n  #write.table(x=total_imp, file=paste(file_dir, \"result/\", \"output \", type, option,\".csv\", sep=\"\"),row.names=TRUE, col.names =TRUE, append=TRUE)\n  \n  #writeLines(text=paste(file_path, result, sep=\"\\t\"), con=fileConn)\n  \n  print(result);\n  #fileConn2 <- file(paste(file_dir, typearr[k],  \"result\", option, \".txt\", sep=\"\"), open=\"at\")\n  #writeLines(text=paste(file_path, result, sep=\"\\t\"), con=fileConn2)\n  #close(fileConn2)\n}\nwriteLines(\"========================================\", con=fileConn)\nclose(fileConn)\n\n",
    "created" : 1487665579521.000,
    "dirty" : false,
    "encoding" : "UTF-8",
    "folds" : "",
    "hash" : "3153662634",
    "id" : "1480B6E5",
    "lastKnownWriteTime" : 1476799946,
    "last_content_update" : 1476799946,
    "path" : "C:/Users/HJJeong/Desktop/experiment/R/linkprediction_wsrf.r",
    "project_path" : null,
    "properties" : {
    },
    "relative_order" : 8,
    "source_on_save" : false,
    "source_window" : "",
    "type" : "r_source"
}